{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trinn/workspace/ml-venv/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',') for row in file\n",
    "        ]], \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    return X_\n",
    "\n",
    "def load_Y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(a, b):\n",
    "    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n",
    "    # if one of two points is (0,0), dist = 0\n",
    "    # a, b: input array with dimension: m, 2\n",
    "    # m: number of samples\n",
    "    # 2: x and y coordinate\n",
    "    try:\n",
    "        if (a.shape[1] == 2 and a.shape == b.shape):\n",
    "            # check if element of a and b is (0,0)\n",
    "            bol_a = (a[:,0] != 0).astype(int)\n",
    "            bol_b = (b[:,0] != 0).astype(int)\n",
    "            dist = np.linalg.norm(a-b, axis=1)\n",
    "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
    "    except:\n",
    "        print(\"[Error]: Check dimension of input vector\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_X(X):\n",
    "    num_sample = X.shape[0]\n",
    "    # Keypoints\n",
    "    Nose = X[:,0*2:0*2+2]\n",
    "    Neck = X[:,1*2:1*2+2]\n",
    "    RShoulder = X[:,2*2:2*2+2]\n",
    "    RElbow = X[:,3*2:3*2+2]\n",
    "    RWrist = X[:,4*2:4*2+2]\n",
    "    LShoulder = X[:,5*2:5*2+2]\n",
    "    LElbow = X[:,6*2:6*2+2]\n",
    "    LWrist = X[:,7*2:7*2+2]\n",
    "    RHip = X[:,8*2:8*2+2]\n",
    "    RKnee = X[:,9*2:9*2+2]\n",
    "    RAnkle = X[:,10*2:10*2+2]\n",
    "    LHip = X[:,11*2:11*2+2]\n",
    "    LKnee = X[:,12*2:12*2+2]\n",
    "    LAnkle = X[:,13*2:13*2+2]\n",
    "    REye = X[:,14*2:14*2+2]\n",
    "    LEye = X[:,15*2:15*2+2]\n",
    "    REar = X[:,16*2:16*2+2]\n",
    "    LEar = X[:,17*2:17*2+2]\n",
    "\n",
    "    # Length of head\n",
    "    length_Neck_LEar = euclidean_dist(Neck, LEar)\n",
    "    length_Neck_REar = euclidean_dist(Neck, REar)\n",
    "    length_Neck_LEye = euclidean_dist(Neck, LEye)\n",
    "    length_Neck_REye = euclidean_dist(Neck, REye)\n",
    "    length_Nose_LEar = euclidean_dist(Nose, LEar)\n",
    "    length_Nose_REar = euclidean_dist(Nose, REar)\n",
    "    length_Nose_LEye = euclidean_dist(Nose, LEye)\n",
    "    length_Nose_REye = euclidean_dist(Nose, REye)\n",
    "    length_head      = np.maximum.reduce([length_Neck_LEar, length_Neck_REar, length_Neck_LEye, length_Neck_REye, \\\n",
    "                                 length_Nose_LEar, length_Nose_REar, length_Nose_LEye, length_Nose_REye])\n",
    "    #length_head      = np.sqrt(np.square((LEye[:,0:1]+REye[:,0:1])/2 - Neck[:,0:1]) + np.square((LEye[:,1:2]+REye[:,1:2])/2 - Neck[:,1:2]))\n",
    "\n",
    "    # Length of torso\n",
    "    length_Neck_LHip = euclidean_dist(Neck, LHip)\n",
    "    length_Neck_RHip = euclidean_dist(Neck, RHip)\n",
    "    length_torso     = np.maximum(length_Neck_LHip, length_Neck_RHip)\n",
    "    #length_torso     = np.sqrt(np.square(Neck[:,0:1]-(LHip[:,0:1]+RHip[:,0:1])/2) + np.square(Neck[:,1:2]-(LHip[:,1:2]+RHip[:,1:2])/2))\n",
    "\n",
    "    # Length of right leg\n",
    "    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n",
    "    #length_leg_right = np.sqrt(np.square(RHip[:,0:1]-RKnee[:,0:1]) + np.square(RHip[:,1:2]-RKnee[:,1:2])) \\\n",
    "    #+ np.sqrt(np.square(RKnee[:,0:1]-RAnkle[:,0:1]) + np.square(RKnee[:,1:2]-RAnkle[:,1:2]))\n",
    "\n",
    "    # Length of left leg\n",
    "    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n",
    "    #length_leg_left = np.sqrt(np.square(LHip[:,0:1]-LKnee[:,0:1]) + np.square(LHip[:,1:2]-LKnee[:,1:2])) \\\n",
    "    #+ np.sqrt(np.square(LKnee[:,0:1]-LAnkle[:,0:1]) + np.square(LKnee[:,1:2]-LAnkle[:,1:2]))\n",
    "\n",
    "    # Length of leg\n",
    "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
    "\n",
    "    # Length of body\n",
    "    length_body = length_head + length_torso + length_leg\n",
    "    \n",
    "    # Check all samples have length_body of 0\n",
    "    length_chk = (length_body > 0).astype(int)\n",
    "    \n",
    "    # Check keypoints at origin\n",
    "    keypoints_chk = (X > 0).astype(int)\n",
    "    \n",
    "    chk = length_chk * keypoints_chk\n",
    "    \n",
    "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
    "    length_body[length_body == 0] = 1\n",
    "    \n",
    "    # The center of gravity\n",
    "    # number of point OpenPose locates:\n",
    "    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n",
    "    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
    "    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n",
    "    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n",
    "    \n",
    "    # Stack 1st element x and y together\n",
    "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n",
    "        \n",
    "    for i in range(1, X.shape[1]//2):\n",
    "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n",
    "    \n",
    "    # Set all samples have length_body of 0 to origin (0, 0)\n",
    "    X_norm = X_norm * chk\n",
    "    \n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(a, b):\n",
    "    if (a.any()> 0 and b.any()>0): plt.plot([a[0], b[0]], [a[1], b[1]], 'k-')\n",
    "        \n",
    "def plot_skeleton(sample, pattern):\n",
    "    for i in range(len(sample)//2):\n",
    "        plt.plot(sample[i*2], sample[i*2+1], pattern) \n",
    "    skeleton = sample.reshape(1, 36)\n",
    "    Nose = skeleton[:,0*2:0*2+2][0]\n",
    "    Neck = skeleton[:,1*2:1*2+2][0]\n",
    "    RShoulder = skeleton[:,2*2:2*2+2][0]\n",
    "    RElbow = skeleton[:,3*2:3*2+2][0]\n",
    "    RWrist = skeleton[:,4*2:4*2+2][0]\n",
    "    LShoulder = skeleton[:,5*2:5*2+2][0]\n",
    "    LElbow = skeleton[:,6*2:6*2+2][0]\n",
    "    LWrist = skeleton[:,7*2:7*2+2][0]\n",
    "    RHip = skeleton[:,8*2:8*2+2][0]\n",
    "    RKnee = skeleton[:,9*2:9*2+2][0]\n",
    "    RAnkle = skeleton[:,10*2:10*2+2][0]\n",
    "    LHip = skeleton[:,11*2:11*2+2][0]\n",
    "    LKnee = skeleton[:,12*2:12*2+2][0]\n",
    "    LAnkle = skeleton[:,13*2:13*2+2][0]\n",
    "    REye = skeleton[:,14*2:14*2+2][0]\n",
    "    LEye = skeleton[:,15*2:15*2+2][0]\n",
    "    REar = skeleton[:,16*2:16*2+2][0]\n",
    "    LEar = skeleton[:,17*2:17*2+2][0]\n",
    "    #Nose = sample.reshape(1, 36)[:,0*2:0*2+2][0]\n",
    "    #Neck = sample.reshape(1, 36)[:,1*2:1*2+2][0]\n",
    "    plot_line(LEar, LEye)\n",
    "    plot_line(LEye, Nose)\n",
    "    plot_line(REar, REye)\n",
    "    plot_line(REye, Nose)\n",
    "    plot_line(Nose, Neck)\n",
    "    plot_line(Neck, LShoulder)\n",
    "    plot_line(LShoulder, LElbow)\n",
    "    plot_line(LElbow, LWrist)\n",
    "    plot_line(Neck, RShoulder)\n",
    "    plot_line(RShoulder, RElbow)\n",
    "    plot_line(RElbow, RWrist)\n",
    "    plot_line(Neck, LHip)\n",
    "    plot_line(LHip, LKnee)\n",
    "    plot_line(LKnee, LAnkle)\n",
    "    plot_line(Neck, RHip)\n",
    "    plot_line(RHip, RKnee)\n",
    "    plot_line(RKnee, RAnkle)\n",
    "    \n",
    "def plot(sample):\n",
    "    # sample is one-dimension array\n",
    "    # e.g: (36,)\n",
    "    if sample.shape[0] == 36:\n",
    "        sample_norm = norm_X(sample.reshape(1,36))[0]\n",
    "\n",
    "        # Plot original coordinates\n",
    "        pad_ori = 40\n",
    "        plt.figure(str(sample))\n",
    "        plt.subplot(121)\n",
    "        plt.title('Original skeleton')\n",
    "        X_ori = sample\n",
    "        x_max = max(X_ori[0::2]) + pad_ori\n",
    "        x_min = min(i for i in X_ori[0::2] if i > 0) - pad_ori\n",
    "        y_max = max(X_ori[1::2]) + pad_ori\n",
    "        y_min = min(j for j in X_ori[1::2] if j > 0) - pad_ori\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_ori, 'bo')\n",
    "\n",
    "        # Plot normalized coordinates\n",
    "        pad_nor = 0.2\n",
    "        #plt.figure(2)\n",
    "        plt.subplot(122)\n",
    "        plt.title('Normalized skeleton')\n",
    "        X_nor = sample_norm\n",
    "        x_max = max(X_nor[0::2]) + pad_nor\n",
    "        x_min = min(X_nor[0::2]) - pad_nor\n",
    "        y_max = max(X_nor[1::2]) + pad_nor\n",
    "        y_min = min(X_nor[1::2]) - pad_nor\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_nor, 'ro')\n",
    "    else:\n",
    "        print(\"sample is one-dimension array: (36,)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                2368      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 5,027\n",
      "Trainable params: 5,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='sigmoid', input_shape=(36,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# plot training log\n",
    "def plot_history(history):\n",
    "    history_dict = history.history\n",
    "    history_dict.keys()\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # \"bo\" is for \"blue dot\"\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    # b is for \"solid blue line\"\n",
    "    plt.plot(epochs, val_loss, 'ro', label='Validation loss')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation loss/acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and norminalize dataset\n",
    "X_train = load_X('dataset/X_train.txt')\n",
    "Y_train = load_Y('dataset/Y_train.txt')\n",
    "X_train_norm = norm_X(X_train)\n",
    "\n",
    "X_test = load_X('dataset/X_test.txt')\n",
    "Y_test = load_Y('dataset/Y_test.txt')\n",
    "X_test_norm = norm_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2676 samples, validate on 701 samples\n",
      "Epoch 1/500\n",
      "2676/2676 [==============================] - 0s 110us/step - loss: 1.0979 - acc: 0.3950 - val_loss: 0.9604 - val_acc: 0.4793\n",
      "Epoch 2/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.8894 - acc: 0.5475 - val_loss: 0.6829 - val_acc: 0.6448\n",
      "Epoch 3/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.7183 - acc: 0.6816 - val_loss: 0.5456 - val_acc: 0.8017\n",
      "Epoch 4/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.6338 - acc: 0.7268 - val_loss: 0.4760 - val_acc: 0.8445\n",
      "Epoch 5/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.5895 - acc: 0.7724 - val_loss: 0.4272 - val_acc: 0.8217\n",
      "Epoch 6/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.5415 - acc: 0.7975 - val_loss: 0.4201 - val_acc: 0.8203\n",
      "Epoch 7/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.5260 - acc: 0.8094 - val_loss: 0.3477 - val_acc: 0.8688\n",
      "Epoch 8/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.4866 - acc: 0.8274 - val_loss: 0.3053 - val_acc: 0.8944\n",
      "Epoch 9/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.4560 - acc: 0.8445 - val_loss: 0.2906 - val_acc: 0.9030\n",
      "Epoch 10/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.4383 - acc: 0.8509 - val_loss: 0.2790 - val_acc: 0.8959\n",
      "Epoch 11/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.4018 - acc: 0.8591 - val_loss: 0.2715 - val_acc: 0.9016\n",
      "Epoch 12/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3967 - acc: 0.8718 - val_loss: 0.2594 - val_acc: 0.9116\n",
      "Epoch 13/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.4069 - acc: 0.8617 - val_loss: 0.2529 - val_acc: 0.9087\n",
      "Epoch 14/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3701 - acc: 0.8808 - val_loss: 0.2427 - val_acc: 0.9087\n",
      "Epoch 15/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3821 - acc: 0.8793 - val_loss: 0.2359 - val_acc: 0.9087\n",
      "Epoch 16/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3788 - acc: 0.8786 - val_loss: 0.2316 - val_acc: 0.9101\n",
      "Epoch 17/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3718 - acc: 0.8853 - val_loss: 0.2395 - val_acc: 0.9130\n",
      "Epoch 18/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3739 - acc: 0.8812 - val_loss: 0.2303 - val_acc: 0.9144\n",
      "Epoch 19/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3585 - acc: 0.8804 - val_loss: 0.2277 - val_acc: 0.9144\n",
      "Epoch 20/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3652 - acc: 0.8842 - val_loss: 0.2284 - val_acc: 0.9116\n",
      "Epoch 21/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.3585 - acc: 0.8819 - val_loss: 0.2289 - val_acc: 0.9158\n",
      "Epoch 22/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3459 - acc: 0.8830 - val_loss: 0.2232 - val_acc: 0.9130\n",
      "Epoch 23/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3286 - acc: 0.8901 - val_loss: 0.2378 - val_acc: 0.9087\n",
      "Epoch 24/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.3496 - acc: 0.8894 - val_loss: 0.2153 - val_acc: 0.9158\n",
      "Epoch 25/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3413 - acc: 0.8894 - val_loss: 0.2239 - val_acc: 0.9158\n",
      "Epoch 26/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3319 - acc: 0.8950 - val_loss: 0.2199 - val_acc: 0.9173\n",
      "Epoch 27/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3296 - acc: 0.8969 - val_loss: 0.2243 - val_acc: 0.9158\n",
      "Epoch 28/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3244 - acc: 0.8987 - val_loss: 0.2175 - val_acc: 0.9144\n",
      "Epoch 29/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3286 - acc: 0.8920 - val_loss: 0.2204 - val_acc: 0.9173\n",
      "Epoch 30/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3175 - acc: 0.8969 - val_loss: 0.2214 - val_acc: 0.9173\n",
      "Epoch 31/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3115 - acc: 0.8939 - val_loss: 0.2205 - val_acc: 0.9173\n",
      "Epoch 32/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3065 - acc: 0.8991 - val_loss: 0.2268 - val_acc: 0.9144\n",
      "Epoch 33/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.3129 - acc: 0.8976 - val_loss: 0.2054 - val_acc: 0.9144\n",
      "Epoch 34/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3056 - acc: 0.8957 - val_loss: 0.2099 - val_acc: 0.9130\n",
      "Epoch 35/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3189 - acc: 0.8946 - val_loss: 0.2173 - val_acc: 0.9230\n",
      "Epoch 36/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3198 - acc: 0.8991 - val_loss: 0.2137 - val_acc: 0.9187\n",
      "Epoch 37/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2970 - acc: 0.8999 - val_loss: 0.2112 - val_acc: 0.9173\n",
      "Epoch 38/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3023 - acc: 0.8980 - val_loss: 0.2079 - val_acc: 0.9173\n",
      "Epoch 39/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3011 - acc: 0.9051 - val_loss: 0.2164 - val_acc: 0.9230\n",
      "Epoch 40/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.3066 - acc: 0.8950 - val_loss: 0.2006 - val_acc: 0.9173\n",
      "Epoch 41/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2837 - acc: 0.9062 - val_loss: 0.2090 - val_acc: 0.9272\n",
      "Epoch 42/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3084 - acc: 0.9088 - val_loss: 0.2026 - val_acc: 0.9158\n",
      "Epoch 43/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2933 - acc: 0.8980 - val_loss: 0.1953 - val_acc: 0.9215\n",
      "Epoch 44/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3053 - acc: 0.8946 - val_loss: 0.1882 - val_acc: 0.9230\n",
      "Epoch 45/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2962 - acc: 0.9010 - val_loss: 0.1897 - val_acc: 0.9215\n",
      "Epoch 46/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2893 - acc: 0.9010 - val_loss: 0.1955 - val_acc: 0.9187\n",
      "Epoch 47/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2965 - acc: 0.8961 - val_loss: 0.1868 - val_acc: 0.9201\n",
      "Epoch 48/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.2983 - acc: 0.9006 - val_loss: 0.1836 - val_acc: 0.9215\n",
      "Epoch 49/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2979 - acc: 0.9032 - val_loss: 0.1849 - val_acc: 0.9230\n",
      "Epoch 50/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2869 - acc: 0.9099 - val_loss: 0.1772 - val_acc: 0.9244\n",
      "Epoch 51/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2782 - acc: 0.9066 - val_loss: 0.1776 - val_acc: 0.9215\n",
      "Epoch 52/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2665 - acc: 0.9137 - val_loss: 0.1837 - val_acc: 0.9458\n",
      "Epoch 53/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2757 - acc: 0.9073 - val_loss: 0.1758 - val_acc: 0.9387\n",
      "Epoch 54/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2721 - acc: 0.9107 - val_loss: 0.1778 - val_acc: 0.9315\n",
      "Epoch 55/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2900 - acc: 0.9118 - val_loss: 0.1851 - val_acc: 0.9272\n",
      "Epoch 56/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2776 - acc: 0.9144 - val_loss: 0.1695 - val_acc: 0.9415\n",
      "Epoch 57/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2808 - acc: 0.9111 - val_loss: 0.1738 - val_acc: 0.9315\n",
      "Epoch 58/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2816 - acc: 0.9036 - val_loss: 0.1789 - val_acc: 0.9344\n",
      "Epoch 59/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2591 - acc: 0.9215 - val_loss: 0.1784 - val_acc: 0.9187\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2639 - acc: 0.9111 - val_loss: 0.1712 - val_acc: 0.9429\n",
      "Epoch 61/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2605 - acc: 0.9234 - val_loss: 0.1712 - val_acc: 0.9501\n",
      "Epoch 62/500\n",
      "2676/2676 [==============================] - 0s 51us/step - loss: 0.2663 - acc: 0.9159 - val_loss: 0.1660 - val_acc: 0.9387\n",
      "Epoch 63/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.2648 - acc: 0.9167 - val_loss: 0.1695 - val_acc: 0.9429\n",
      "Epoch 64/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2599 - acc: 0.9129 - val_loss: 0.1744 - val_acc: 0.9458\n",
      "Epoch 65/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2603 - acc: 0.9148 - val_loss: 0.1642 - val_acc: 0.9429\n",
      "Epoch 66/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2567 - acc: 0.9193 - val_loss: 0.1677 - val_acc: 0.9444\n",
      "Epoch 67/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2588 - acc: 0.9215 - val_loss: 0.1643 - val_acc: 0.9429\n",
      "Epoch 68/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2500 - acc: 0.9204 - val_loss: 0.1695 - val_acc: 0.9415\n",
      "Epoch 69/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2648 - acc: 0.9137 - val_loss: 0.1611 - val_acc: 0.9515\n",
      "Epoch 70/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2597 - acc: 0.9182 - val_loss: 0.1571 - val_acc: 0.9472\n",
      "Epoch 71/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2444 - acc: 0.9271 - val_loss: 0.1602 - val_acc: 0.9486\n",
      "Epoch 72/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2566 - acc: 0.9167 - val_loss: 0.1567 - val_acc: 0.9444\n",
      "Epoch 73/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2425 - acc: 0.9208 - val_loss: 0.1600 - val_acc: 0.9458\n",
      "Epoch 74/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2502 - acc: 0.9219 - val_loss: 0.1563 - val_acc: 0.9515\n",
      "Epoch 75/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2519 - acc: 0.9178 - val_loss: 0.1530 - val_acc: 0.9444\n",
      "Epoch 76/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2633 - acc: 0.9103 - val_loss: 0.1500 - val_acc: 0.9501\n",
      "Epoch 77/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2417 - acc: 0.9215 - val_loss: 0.1597 - val_acc: 0.9444\n",
      "Epoch 78/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2404 - acc: 0.9219 - val_loss: 0.1549 - val_acc: 0.9486\n",
      "Epoch 79/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2324 - acc: 0.9260 - val_loss: 0.1557 - val_acc: 0.9486\n",
      "Epoch 80/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2516 - acc: 0.9238 - val_loss: 0.1535 - val_acc: 0.9458\n",
      "Epoch 81/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2405 - acc: 0.9249 - val_loss: 0.1544 - val_acc: 0.9501\n",
      "Epoch 82/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2471 - acc: 0.9290 - val_loss: 0.1620 - val_acc: 0.9444\n",
      "Epoch 83/500\n",
      "2676/2676 [==============================] - 0s 57us/step - loss: 0.2272 - acc: 0.9286 - val_loss: 0.1712 - val_acc: 0.9501\n",
      "Epoch 84/500\n",
      "2676/2676 [==============================] - 0s 58us/step - loss: 0.2525 - acc: 0.9245 - val_loss: 0.1560 - val_acc: 0.9458\n",
      "Epoch 85/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2494 - acc: 0.9215 - val_loss: 0.1490 - val_acc: 0.9472\n",
      "Epoch 86/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2343 - acc: 0.9283 - val_loss: 0.1471 - val_acc: 0.9444\n",
      "Epoch 87/500\n",
      "2676/2676 [==============================] - 0s 57us/step - loss: 0.2418 - acc: 0.9241 - val_loss: 0.1542 - val_acc: 0.9472\n",
      "Epoch 88/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.2468 - acc: 0.9264 - val_loss: 0.1490 - val_acc: 0.9486\n",
      "Epoch 89/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.2294 - acc: 0.9312 - val_loss: 0.1584 - val_acc: 0.9529\n",
      "Epoch 90/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2522 - acc: 0.9223 - val_loss: 0.1518 - val_acc: 0.9501\n",
      "Epoch 91/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2294 - acc: 0.9286 - val_loss: 0.1625 - val_acc: 0.9472\n",
      "Epoch 92/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.2294 - acc: 0.9253 - val_loss: 0.1562 - val_acc: 0.9472\n",
      "Epoch 93/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2203 - acc: 0.9331 - val_loss: 0.1568 - val_acc: 0.9515\n",
      "Epoch 94/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2396 - acc: 0.9286 - val_loss: 0.1485 - val_acc: 0.9501\n",
      "Epoch 95/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2193 - acc: 0.9354 - val_loss: 0.1633 - val_acc: 0.9515\n",
      "Epoch 96/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2552 - acc: 0.9275 - val_loss: 0.1500 - val_acc: 0.9515\n",
      "Epoch 97/500\n",
      "2676/2676 [==============================] - 0s 59us/step - loss: 0.2283 - acc: 0.9309 - val_loss: 0.1583 - val_acc: 0.9558\n",
      "Epoch 98/500\n",
      "2676/2676 [==============================] - 0s 63us/step - loss: 0.2473 - acc: 0.9178 - val_loss: 0.1528 - val_acc: 0.9529\n",
      "Epoch 99/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2166 - acc: 0.9376 - val_loss: 0.1514 - val_acc: 0.9529\n",
      "Epoch 100/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2272 - acc: 0.9297 - val_loss: 0.1498 - val_acc: 0.9529\n",
      "Epoch 101/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2387 - acc: 0.9279 - val_loss: 0.1463 - val_acc: 0.9501\n",
      "Epoch 102/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2323 - acc: 0.9320 - val_loss: 0.1556 - val_acc: 0.9472\n",
      "Epoch 103/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.2283 - acc: 0.9342 - val_loss: 0.1457 - val_acc: 0.9501\n",
      "Epoch 104/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2197 - acc: 0.9286 - val_loss: 0.1473 - val_acc: 0.9515\n",
      "Epoch 105/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2197 - acc: 0.9365 - val_loss: 0.1644 - val_acc: 0.9501\n",
      "Epoch 106/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2461 - acc: 0.9301 - val_loss: 0.1544 - val_acc: 0.9515\n",
      "Epoch 107/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2288 - acc: 0.9253 - val_loss: 0.1583 - val_acc: 0.9529\n",
      "Epoch 108/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2170 - acc: 0.9354 - val_loss: 0.1552 - val_acc: 0.9472\n",
      "Epoch 109/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2165 - acc: 0.9324 - val_loss: 0.1418 - val_acc: 0.9529\n",
      "Epoch 110/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2311 - acc: 0.9335 - val_loss: 0.1441 - val_acc: 0.9529\n",
      "Epoch 111/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2225 - acc: 0.9316 - val_loss: 0.1428 - val_acc: 0.9515\n",
      "Epoch 112/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2283 - acc: 0.9305 - val_loss: 0.1503 - val_acc: 0.9529\n",
      "Epoch 113/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2106 - acc: 0.9372 - val_loss: 0.1402 - val_acc: 0.9615\n",
      "Epoch 114/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2062 - acc: 0.9376 - val_loss: 0.1495 - val_acc: 0.9544\n",
      "Epoch 115/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2265 - acc: 0.9346 - val_loss: 0.1543 - val_acc: 0.9558\n",
      "Epoch 116/500\n",
      "2676/2676 [==============================] - 0s 85us/step - loss: 0.2373 - acc: 0.9320 - val_loss: 0.1522 - val_acc: 0.9544\n",
      "Epoch 117/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2311 - acc: 0.9346 - val_loss: 0.1435 - val_acc: 0.9486\n",
      "Epoch 118/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2091 - acc: 0.9413 - val_loss: 0.1457 - val_acc: 0.9572\n",
      "Epoch 119/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2095 - acc: 0.9410 - val_loss: 0.1440 - val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2203 - acc: 0.9324 - val_loss: 0.1452 - val_acc: 0.9458\n",
      "Epoch 121/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2094 - acc: 0.9354 - val_loss: 0.1480 - val_acc: 0.9529\n",
      "Epoch 122/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2232 - acc: 0.9309 - val_loss: 0.1489 - val_acc: 0.9458\n",
      "Epoch 123/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2208 - acc: 0.9350 - val_loss: 0.1555 - val_acc: 0.9458\n",
      "Epoch 124/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2257 - acc: 0.9387 - val_loss: 0.1416 - val_acc: 0.9529\n",
      "Epoch 125/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.2108 - acc: 0.9357 - val_loss: 0.1502 - val_acc: 0.9501\n",
      "Epoch 126/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2414 - acc: 0.9309 - val_loss: 0.1546 - val_acc: 0.9458\n",
      "Epoch 127/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2160 - acc: 0.9380 - val_loss: 0.1456 - val_acc: 0.9472\n",
      "Epoch 128/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2199 - acc: 0.9335 - val_loss: 0.1471 - val_acc: 0.9529\n",
      "Epoch 129/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2288 - acc: 0.9316 - val_loss: 0.1544 - val_acc: 0.9472\n",
      "Epoch 130/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2307 - acc: 0.9331 - val_loss: 0.1420 - val_acc: 0.9486\n",
      "Epoch 131/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.2122 - acc: 0.9342 - val_loss: 0.1400 - val_acc: 0.9501\n",
      "Epoch 132/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2130 - acc: 0.9361 - val_loss: 0.1498 - val_acc: 0.9572\n",
      "Epoch 133/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2195 - acc: 0.9395 - val_loss: 0.1384 - val_acc: 0.9558\n",
      "Epoch 134/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2401 - acc: 0.9312 - val_loss: 0.1438 - val_acc: 0.9544\n",
      "Epoch 135/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2111 - acc: 0.9458 - val_loss: 0.1394 - val_acc: 0.9544\n",
      "Epoch 136/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2206 - acc: 0.9346 - val_loss: 0.1388 - val_acc: 0.9615\n",
      "Epoch 137/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2166 - acc: 0.9331 - val_loss: 0.1450 - val_acc: 0.9501\n",
      "Epoch 138/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2095 - acc: 0.9417 - val_loss: 0.1370 - val_acc: 0.9529\n",
      "Epoch 139/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2288 - acc: 0.9331 - val_loss: 0.1413 - val_acc: 0.9558\n",
      "Epoch 140/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.2050 - acc: 0.9391 - val_loss: 0.1493 - val_acc: 0.9615\n",
      "Epoch 141/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2164 - acc: 0.9395 - val_loss: 0.1360 - val_acc: 0.9586\n",
      "Epoch 142/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2177 - acc: 0.9316 - val_loss: 0.1376 - val_acc: 0.9615\n",
      "Epoch 143/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.1911 - acc: 0.9447 - val_loss: 0.1475 - val_acc: 0.9572\n",
      "Epoch 144/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2115 - acc: 0.9368 - val_loss: 0.1355 - val_acc: 0.9601\n",
      "Epoch 145/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2266 - acc: 0.9283 - val_loss: 0.1403 - val_acc: 0.9572\n",
      "Epoch 146/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2369 - acc: 0.9376 - val_loss: 0.1371 - val_acc: 0.9558\n",
      "Epoch 147/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2029 - acc: 0.9372 - val_loss: 0.1332 - val_acc: 0.9586\n",
      "Epoch 148/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1978 - acc: 0.9380 - val_loss: 0.1392 - val_acc: 0.9643\n",
      "Epoch 149/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1880 - acc: 0.9391 - val_loss: 0.1414 - val_acc: 0.9544\n",
      "Epoch 150/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2036 - acc: 0.9342 - val_loss: 0.1462 - val_acc: 0.9572\n",
      "Epoch 151/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2304 - acc: 0.9320 - val_loss: 0.1405 - val_acc: 0.9586\n",
      "Epoch 152/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2170 - acc: 0.9368 - val_loss: 0.1436 - val_acc: 0.9529\n",
      "Epoch 153/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2159 - acc: 0.9357 - val_loss: 0.1451 - val_acc: 0.9586\n",
      "Epoch 154/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2059 - acc: 0.9361 - val_loss: 0.1489 - val_acc: 0.9529\n",
      "Epoch 155/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2193 - acc: 0.9421 - val_loss: 0.1377 - val_acc: 0.9544\n",
      "Epoch 156/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2206 - acc: 0.9357 - val_loss: 0.1531 - val_acc: 0.9472\n",
      "Epoch 157/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1891 - acc: 0.9421 - val_loss: 0.1473 - val_acc: 0.9615\n",
      "Epoch 158/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1964 - acc: 0.9417 - val_loss: 0.1413 - val_acc: 0.9629\n",
      "Epoch 159/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2085 - acc: 0.9454 - val_loss: 0.1371 - val_acc: 0.9586\n",
      "Epoch 160/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1911 - acc: 0.9387 - val_loss: 0.1443 - val_acc: 0.9572\n",
      "Epoch 161/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2198 - acc: 0.9335 - val_loss: 0.1267 - val_acc: 0.9586\n",
      "Epoch 162/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1968 - acc: 0.9402 - val_loss: 0.1339 - val_acc: 0.9601\n",
      "Epoch 163/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1875 - acc: 0.9443 - val_loss: 0.1342 - val_acc: 0.9558\n",
      "Epoch 164/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1967 - acc: 0.9357 - val_loss: 0.1336 - val_acc: 0.9629\n",
      "Epoch 165/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1998 - acc: 0.9402 - val_loss: 0.1298 - val_acc: 0.9629\n",
      "Epoch 166/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1941 - acc: 0.9425 - val_loss: 0.1325 - val_acc: 0.9558\n",
      "Epoch 167/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1915 - acc: 0.9421 - val_loss: 0.1456 - val_acc: 0.9529\n",
      "Epoch 168/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1819 - acc: 0.9443 - val_loss: 0.1333 - val_acc: 0.9629\n",
      "Epoch 169/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2061 - acc: 0.9406 - val_loss: 0.1290 - val_acc: 0.9643\n",
      "Epoch 170/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2034 - acc: 0.9391 - val_loss: 0.1345 - val_acc: 0.9544\n",
      "Epoch 171/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1916 - acc: 0.9466 - val_loss: 0.1397 - val_acc: 0.9572\n",
      "Epoch 172/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2080 - acc: 0.9380 - val_loss: 0.1349 - val_acc: 0.9558\n",
      "Epoch 173/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2051 - acc: 0.9425 - val_loss: 0.1297 - val_acc: 0.9572\n",
      "Epoch 174/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2038 - acc: 0.9432 - val_loss: 0.1348 - val_acc: 0.9572\n",
      "Epoch 175/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2084 - acc: 0.9346 - val_loss: 0.1340 - val_acc: 0.9629\n",
      "Epoch 176/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1995 - acc: 0.9413 - val_loss: 0.1396 - val_acc: 0.9615\n",
      "Epoch 177/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2021 - acc: 0.9395 - val_loss: 0.1435 - val_acc: 0.9586\n",
      "Epoch 178/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2093 - acc: 0.9301 - val_loss: 0.1353 - val_acc: 0.9615\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1919 - acc: 0.9413 - val_loss: 0.1382 - val_acc: 0.9629\n",
      "Epoch 180/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2078 - acc: 0.9383 - val_loss: 0.1298 - val_acc: 0.9643\n",
      "Epoch 181/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1879 - acc: 0.9421 - val_loss: 0.1424 - val_acc: 0.9572\n",
      "Epoch 182/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1965 - acc: 0.9425 - val_loss: 0.1377 - val_acc: 0.9586\n",
      "Epoch 183/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1999 - acc: 0.9432 - val_loss: 0.1408 - val_acc: 0.9615\n",
      "Epoch 184/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1947 - acc: 0.9413 - val_loss: 0.1423 - val_acc: 0.9558\n",
      "Epoch 185/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.2136 - acc: 0.9335 - val_loss: 0.1303 - val_acc: 0.9572\n",
      "Epoch 186/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1880 - acc: 0.9425 - val_loss: 0.1332 - val_acc: 0.9601\n",
      "Epoch 187/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1880 - acc: 0.9443 - val_loss: 0.1311 - val_acc: 0.9615\n",
      "Epoch 188/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1988 - acc: 0.9383 - val_loss: 0.1388 - val_acc: 0.9615\n",
      "Epoch 189/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2015 - acc: 0.9421 - val_loss: 0.1310 - val_acc: 0.9643\n",
      "Epoch 190/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1910 - acc: 0.9451 - val_loss: 0.1343 - val_acc: 0.9629\n",
      "Epoch 191/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1869 - acc: 0.9398 - val_loss: 0.1282 - val_acc: 0.9643\n",
      "Epoch 192/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1964 - acc: 0.9421 - val_loss: 0.1300 - val_acc: 0.9586\n",
      "Epoch 193/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1899 - acc: 0.9436 - val_loss: 0.1311 - val_acc: 0.9615\n",
      "Epoch 194/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1806 - acc: 0.9473 - val_loss: 0.1382 - val_acc: 0.9615\n",
      "Epoch 195/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1955 - acc: 0.9410 - val_loss: 0.1409 - val_acc: 0.9629\n",
      "Epoch 196/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1881 - acc: 0.9413 - val_loss: 0.1351 - val_acc: 0.9615\n",
      "Epoch 197/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1913 - acc: 0.9514 - val_loss: 0.1382 - val_acc: 0.9529\n",
      "Epoch 198/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1877 - acc: 0.9432 - val_loss: 0.1329 - val_acc: 0.9572\n",
      "Epoch 199/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1882 - acc: 0.9458 - val_loss: 0.1325 - val_acc: 0.9586\n",
      "Epoch 200/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1983 - acc: 0.9410 - val_loss: 0.1309 - val_acc: 0.9572\n",
      "Epoch 201/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1767 - acc: 0.9428 - val_loss: 0.1345 - val_acc: 0.9629\n",
      "Epoch 202/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1886 - acc: 0.9466 - val_loss: 0.1292 - val_acc: 0.9615\n",
      "Epoch 203/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1994 - acc: 0.9428 - val_loss: 0.1243 - val_acc: 0.9615\n",
      "Epoch 204/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1944 - acc: 0.9428 - val_loss: 0.1213 - val_acc: 0.9615\n",
      "Epoch 205/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1743 - acc: 0.9507 - val_loss: 0.1368 - val_acc: 0.9572\n",
      "Epoch 206/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1856 - acc: 0.9466 - val_loss: 0.1429 - val_acc: 0.9544\n",
      "Epoch 207/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2059 - acc: 0.9421 - val_loss: 0.1291 - val_acc: 0.9601\n",
      "Epoch 208/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1882 - acc: 0.9469 - val_loss: 0.1307 - val_acc: 0.9615\n",
      "Epoch 209/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1920 - acc: 0.9447 - val_loss: 0.1269 - val_acc: 0.9615\n",
      "Epoch 210/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2000 - acc: 0.9492 - val_loss: 0.1323 - val_acc: 0.9615\n",
      "Epoch 211/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1832 - acc: 0.9462 - val_loss: 0.1316 - val_acc: 0.9629\n",
      "Epoch 212/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2025 - acc: 0.9425 - val_loss: 0.1236 - val_acc: 0.9601\n",
      "Epoch 213/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1929 - acc: 0.9428 - val_loss: 0.1438 - val_acc: 0.9601\n",
      "Epoch 214/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1989 - acc: 0.9372 - val_loss: 0.1253 - val_acc: 0.9643\n",
      "Epoch 215/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1698 - acc: 0.9510 - val_loss: 0.1383 - val_acc: 0.9629\n",
      "Epoch 216/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1960 - acc: 0.9443 - val_loss: 0.1330 - val_acc: 0.9629\n",
      "Epoch 217/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1802 - acc: 0.9473 - val_loss: 0.1324 - val_acc: 0.9643\n",
      "Epoch 218/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1913 - acc: 0.9413 - val_loss: 0.1268 - val_acc: 0.9615\n",
      "Epoch 219/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1773 - acc: 0.9510 - val_loss: 0.1342 - val_acc: 0.9629\n",
      "Epoch 220/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1920 - acc: 0.9462 - val_loss: 0.1438 - val_acc: 0.9601\n",
      "Epoch 221/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1972 - acc: 0.9439 - val_loss: 0.1298 - val_acc: 0.9629\n",
      "Epoch 222/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1922 - acc: 0.9425 - val_loss: 0.1360 - val_acc: 0.9586\n",
      "Epoch 223/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1772 - acc: 0.9413 - val_loss: 0.1311 - val_acc: 0.9629\n",
      "Epoch 224/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1767 - acc: 0.9499 - val_loss: 0.1416 - val_acc: 0.9615\n",
      "Epoch 225/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1763 - acc: 0.9496 - val_loss: 0.1430 - val_acc: 0.9643\n",
      "Epoch 226/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1852 - acc: 0.9454 - val_loss: 0.1300 - val_acc: 0.9601\n",
      "Epoch 227/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1689 - acc: 0.9552 - val_loss: 0.1273 - val_acc: 0.9629\n",
      "Epoch 228/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1869 - acc: 0.9492 - val_loss: 0.1246 - val_acc: 0.9629\n",
      "Epoch 229/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1722 - acc: 0.9510 - val_loss: 0.1426 - val_acc: 0.9629\n",
      "Epoch 230/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1781 - acc: 0.9477 - val_loss: 0.1291 - val_acc: 0.9629\n",
      "Epoch 231/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1897 - acc: 0.9451 - val_loss: 0.1291 - val_acc: 0.9601\n",
      "Epoch 232/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1701 - acc: 0.9469 - val_loss: 0.1332 - val_acc: 0.9615\n",
      "Epoch 233/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1879 - acc: 0.9466 - val_loss: 0.1305 - val_acc: 0.9629\n",
      "Epoch 234/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1748 - acc: 0.9514 - val_loss: 0.1325 - val_acc: 0.9643\n",
      "Epoch 235/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1917 - acc: 0.9439 - val_loss: 0.1320 - val_acc: 0.9586\n",
      "Epoch 236/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1929 - acc: 0.9421 - val_loss: 0.1261 - val_acc: 0.9601\n",
      "Epoch 237/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1822 - acc: 0.9425 - val_loss: 0.1247 - val_acc: 0.9643\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1776 - acc: 0.9481 - val_loss: 0.1300 - val_acc: 0.9643\n",
      "Epoch 239/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1744 - acc: 0.9496 - val_loss: 0.1344 - val_acc: 0.9629\n",
      "Epoch 240/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1819 - acc: 0.9473 - val_loss: 0.1397 - val_acc: 0.9629\n",
      "Epoch 241/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1570 - acc: 0.9533 - val_loss: 0.1641 - val_acc: 0.9615\n",
      "Epoch 242/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1559 - acc: 0.9555 - val_loss: 0.1406 - val_acc: 0.9601\n",
      "Epoch 243/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1937 - acc: 0.9410 - val_loss: 0.1278 - val_acc: 0.9586\n",
      "Epoch 244/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1900 - acc: 0.9432 - val_loss: 0.1371 - val_acc: 0.9615\n",
      "Epoch 245/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1728 - acc: 0.9484 - val_loss: 0.1368 - val_acc: 0.9601\n",
      "Epoch 246/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1882 - acc: 0.9462 - val_loss: 0.1382 - val_acc: 0.9601\n",
      "Epoch 247/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1963 - acc: 0.9451 - val_loss: 0.1399 - val_acc: 0.9601\n",
      "Epoch 248/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1651 - acc: 0.9533 - val_loss: 0.1624 - val_acc: 0.9586\n",
      "Epoch 249/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1836 - acc: 0.9496 - val_loss: 0.1445 - val_acc: 0.9586\n",
      "Epoch 250/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1965 - acc: 0.9454 - val_loss: 0.1304 - val_acc: 0.9601\n",
      "Epoch 251/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1654 - acc: 0.9499 - val_loss: 0.1274 - val_acc: 0.9586\n",
      "Epoch 252/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1763 - acc: 0.9537 - val_loss: 0.1337 - val_acc: 0.9643\n",
      "Epoch 253/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1702 - acc: 0.9484 - val_loss: 0.1567 - val_acc: 0.9601\n",
      "Epoch 254/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1676 - acc: 0.9525 - val_loss: 0.1395 - val_acc: 0.9615\n",
      "Epoch 255/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1653 - acc: 0.9537 - val_loss: 0.1298 - val_acc: 0.9615\n",
      "Epoch 256/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1720 - acc: 0.9529 - val_loss: 0.1370 - val_acc: 0.9601\n",
      "Epoch 257/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1900 - acc: 0.9458 - val_loss: 0.1561 - val_acc: 0.9586\n",
      "Epoch 258/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1812 - acc: 0.9544 - val_loss: 0.1300 - val_acc: 0.9629\n",
      "Epoch 259/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1854 - acc: 0.9499 - val_loss: 0.1403 - val_acc: 0.9544\n",
      "Epoch 260/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1718 - acc: 0.9510 - val_loss: 0.1497 - val_acc: 0.9558\n",
      "Epoch 261/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1605 - acc: 0.9525 - val_loss: 0.1229 - val_acc: 0.9643\n",
      "Epoch 262/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1626 - acc: 0.9484 - val_loss: 0.1295 - val_acc: 0.9643\n",
      "Epoch 263/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1674 - acc: 0.9507 - val_loss: 0.1226 - val_acc: 0.9643\n",
      "Epoch 264/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1783 - acc: 0.9421 - val_loss: 0.1224 - val_acc: 0.9586\n",
      "Epoch 265/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1656 - acc: 0.9525 - val_loss: 0.1261 - val_acc: 0.9615\n",
      "Epoch 266/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1778 - acc: 0.9518 - val_loss: 0.1206 - val_acc: 0.9615\n",
      "Epoch 267/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1687 - acc: 0.9533 - val_loss: 0.1332 - val_acc: 0.9586\n",
      "Epoch 268/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1865 - acc: 0.9507 - val_loss: 0.1190 - val_acc: 0.9629\n",
      "Epoch 269/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1722 - acc: 0.9439 - val_loss: 0.1254 - val_acc: 0.9629\n",
      "Epoch 270/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1939 - acc: 0.9473 - val_loss: 0.1279 - val_acc: 0.9643\n",
      "Epoch 271/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1732 - acc: 0.9488 - val_loss: 0.1243 - val_acc: 0.9643\n",
      "Epoch 272/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1633 - acc: 0.9529 - val_loss: 0.1264 - val_acc: 0.9643\n",
      "Epoch 273/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1899 - acc: 0.9462 - val_loss: 0.1205 - val_acc: 0.9629\n",
      "Epoch 274/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1708 - acc: 0.9514 - val_loss: 0.1341 - val_acc: 0.9629\n",
      "Epoch 275/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1428 - acc: 0.9537 - val_loss: 0.1275 - val_acc: 0.9615\n",
      "Epoch 276/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1672 - acc: 0.9525 - val_loss: 0.1319 - val_acc: 0.9643\n",
      "Epoch 277/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1789 - acc: 0.9484 - val_loss: 0.1359 - val_acc: 0.9586\n",
      "Epoch 278/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1935 - acc: 0.9443 - val_loss: 0.1302 - val_acc: 0.9629\n",
      "Epoch 279/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1567 - acc: 0.9567 - val_loss: 0.1319 - val_acc: 0.9643\n",
      "Epoch 280/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1668 - acc: 0.9533 - val_loss: 0.1321 - val_acc: 0.9658\n",
      "Epoch 281/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1829 - acc: 0.9432 - val_loss: 0.1401 - val_acc: 0.9615\n",
      "Epoch 282/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1702 - acc: 0.9507 - val_loss: 0.1221 - val_acc: 0.9615\n",
      "Epoch 283/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1591 - acc: 0.9555 - val_loss: 0.1343 - val_acc: 0.9601\n",
      "Epoch 284/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1767 - acc: 0.9469 - val_loss: 0.1345 - val_acc: 0.9629\n",
      "Epoch 285/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1592 - acc: 0.9552 - val_loss: 0.1432 - val_acc: 0.9615\n",
      "Epoch 286/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1725 - acc: 0.9525 - val_loss: 0.1344 - val_acc: 0.9643\n",
      "Epoch 287/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1559 - acc: 0.9552 - val_loss: 0.1427 - val_acc: 0.9643\n",
      "Epoch 288/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1518 - acc: 0.9548 - val_loss: 0.1478 - val_acc: 0.9601\n",
      "Epoch 289/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1945 - acc: 0.9447 - val_loss: 0.1299 - val_acc: 0.9615\n",
      "Epoch 290/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1740 - acc: 0.9458 - val_loss: 0.1253 - val_acc: 0.9586\n",
      "Epoch 291/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1552 - acc: 0.9552 - val_loss: 0.1418 - val_acc: 0.9615\n",
      "Epoch 292/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1737 - acc: 0.9484 - val_loss: 0.1407 - val_acc: 0.9643\n",
      "Epoch 293/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1583 - acc: 0.9537 - val_loss: 0.1408 - val_acc: 0.9601\n",
      "Epoch 294/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1701 - acc: 0.9540 - val_loss: 0.1394 - val_acc: 0.9629\n",
      "Epoch 295/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1984 - acc: 0.9454 - val_loss: 0.1303 - val_acc: 0.9629\n",
      "Epoch 296/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1640 - acc: 0.9529 - val_loss: 0.1475 - val_acc: 0.9601\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1594 - acc: 0.9533 - val_loss: 0.1491 - val_acc: 0.9601\n",
      "Epoch 298/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1626 - acc: 0.9533 - val_loss: 0.1617 - val_acc: 0.9601\n",
      "Epoch 299/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1606 - acc: 0.9503 - val_loss: 0.1604 - val_acc: 0.9629\n",
      "Epoch 300/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1576 - acc: 0.9548 - val_loss: 0.1364 - val_acc: 0.9658\n",
      "Epoch 301/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1859 - acc: 0.9492 - val_loss: 0.1487 - val_acc: 0.9601\n",
      "Epoch 302/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1775 - acc: 0.9510 - val_loss: 0.1559 - val_acc: 0.9615\n",
      "Epoch 303/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1482 - acc: 0.9600 - val_loss: 0.1531 - val_acc: 0.9615\n",
      "Epoch 304/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1666 - acc: 0.9540 - val_loss: 0.1398 - val_acc: 0.9629\n",
      "Epoch 305/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1651 - acc: 0.9529 - val_loss: 0.1428 - val_acc: 0.9629\n",
      "Epoch 306/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1878 - acc: 0.9413 - val_loss: 0.1408 - val_acc: 0.9643\n",
      "Epoch 307/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1650 - acc: 0.9555 - val_loss: 0.1388 - val_acc: 0.9629\n",
      "Epoch 308/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1785 - acc: 0.9488 - val_loss: 0.1337 - val_acc: 0.9643\n",
      "Epoch 309/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1598 - acc: 0.9563 - val_loss: 0.1343 - val_acc: 0.9629\n",
      "Epoch 310/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1729 - acc: 0.9484 - val_loss: 0.1407 - val_acc: 0.9558\n",
      "Epoch 311/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1575 - acc: 0.9578 - val_loss: 0.1398 - val_acc: 0.9586\n",
      "Epoch 312/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1458 - acc: 0.9544 - val_loss: 0.1417 - val_acc: 0.9601\n",
      "Epoch 313/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1711 - acc: 0.9533 - val_loss: 0.1559 - val_acc: 0.9586\n",
      "Epoch 314/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1694 - acc: 0.9514 - val_loss: 0.1335 - val_acc: 0.9629\n",
      "Epoch 315/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1535 - acc: 0.9537 - val_loss: 0.1616 - val_acc: 0.9586\n",
      "Epoch 316/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1364 - acc: 0.9608 - val_loss: 0.1556 - val_acc: 0.9601\n",
      "Epoch 317/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1627 - acc: 0.9525 - val_loss: 0.1352 - val_acc: 0.9601\n",
      "Epoch 318/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1793 - acc: 0.9477 - val_loss: 0.1518 - val_acc: 0.9572\n",
      "Epoch 319/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1586 - acc: 0.9559 - val_loss: 0.1374 - val_acc: 0.9672\n",
      "Epoch 320/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1596 - acc: 0.9555 - val_loss: 0.1278 - val_acc: 0.9615\n",
      "Epoch 321/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1710 - acc: 0.9514 - val_loss: 0.1343 - val_acc: 0.9629\n",
      "Epoch 322/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1728 - acc: 0.9529 - val_loss: 0.1226 - val_acc: 0.9629\n",
      "Epoch 323/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1770 - acc: 0.9499 - val_loss: 0.1287 - val_acc: 0.9658\n",
      "Epoch 324/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1632 - acc: 0.9503 - val_loss: 0.1322 - val_acc: 0.9629\n",
      "Epoch 325/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1682 - acc: 0.9537 - val_loss: 0.1364 - val_acc: 0.9615\n",
      "Epoch 326/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1494 - acc: 0.9581 - val_loss: 0.1639 - val_acc: 0.9615\n",
      "Epoch 327/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1758 - acc: 0.9514 - val_loss: 0.1379 - val_acc: 0.9658\n",
      "Epoch 328/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1656 - acc: 0.9563 - val_loss: 0.1294 - val_acc: 0.9629\n",
      "Epoch 329/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1517 - acc: 0.9570 - val_loss: 0.1436 - val_acc: 0.9586\n",
      "Epoch 330/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1673 - acc: 0.9540 - val_loss: 0.1375 - val_acc: 0.9586\n",
      "Epoch 331/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1577 - acc: 0.9567 - val_loss: 0.1417 - val_acc: 0.9586\n",
      "Epoch 332/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1543 - acc: 0.9581 - val_loss: 0.1222 - val_acc: 0.9572\n",
      "Epoch 333/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1699 - acc: 0.9529 - val_loss: 0.1452 - val_acc: 0.9558\n",
      "Epoch 334/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1600 - acc: 0.9574 - val_loss: 0.1335 - val_acc: 0.9586\n",
      "Epoch 335/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1795 - acc: 0.9533 - val_loss: 0.1461 - val_acc: 0.9586\n",
      "Epoch 336/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1646 - acc: 0.9563 - val_loss: 0.1440 - val_acc: 0.9572\n",
      "Epoch 337/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1489 - acc: 0.9630 - val_loss: 0.1567 - val_acc: 0.9601\n",
      "Epoch 338/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1583 - acc: 0.9552 - val_loss: 0.1519 - val_acc: 0.9629\n",
      "Epoch 339/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1604 - acc: 0.9544 - val_loss: 0.1339 - val_acc: 0.9615\n",
      "Epoch 340/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1448 - acc: 0.9600 - val_loss: 0.1309 - val_acc: 0.9586\n",
      "Epoch 341/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1627 - acc: 0.9510 - val_loss: 0.1388 - val_acc: 0.9601\n",
      "Epoch 342/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1868 - acc: 0.9525 - val_loss: 0.1176 - val_acc: 0.9601\n",
      "Epoch 343/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1549 - acc: 0.9548 - val_loss: 0.1179 - val_acc: 0.9643\n",
      "Epoch 344/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1596 - acc: 0.9563 - val_loss: 0.1273 - val_acc: 0.9629\n",
      "Epoch 345/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1632 - acc: 0.9507 - val_loss: 0.1318 - val_acc: 0.9601\n",
      "Epoch 346/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1644 - acc: 0.9563 - val_loss: 0.1331 - val_acc: 0.9629\n",
      "Epoch 347/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1556 - acc: 0.9585 - val_loss: 0.1279 - val_acc: 0.9643\n",
      "Epoch 348/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1759 - acc: 0.9544 - val_loss: 0.1253 - val_acc: 0.9601\n",
      "Epoch 349/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1637 - acc: 0.9578 - val_loss: 0.1162 - val_acc: 0.9601\n",
      "Epoch 350/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1579 - acc: 0.9537 - val_loss: 0.1299 - val_acc: 0.9601\n",
      "Epoch 351/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1526 - acc: 0.9581 - val_loss: 0.1303 - val_acc: 0.9586\n",
      "Epoch 352/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1585 - acc: 0.9563 - val_loss: 0.1448 - val_acc: 0.9586\n",
      "Epoch 353/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1681 - acc: 0.9525 - val_loss: 0.1477 - val_acc: 0.9586\n",
      "Epoch 354/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1469 - acc: 0.9581 - val_loss: 0.1201 - val_acc: 0.9601\n",
      "Epoch 355/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1475 - acc: 0.9615 - val_loss: 0.1488 - val_acc: 0.9586\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1430 - acc: 0.9589 - val_loss: 0.1491 - val_acc: 0.9586\n",
      "Epoch 357/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1437 - acc: 0.9619 - val_loss: 0.1290 - val_acc: 0.9629\n",
      "Epoch 358/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1877 - acc: 0.9503 - val_loss: 0.1260 - val_acc: 0.9572\n",
      "Epoch 359/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1602 - acc: 0.9611 - val_loss: 0.1482 - val_acc: 0.9601\n",
      "Epoch 360/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1478 - acc: 0.9600 - val_loss: 0.1592 - val_acc: 0.9601\n",
      "Epoch 361/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1486 - acc: 0.9611 - val_loss: 0.1511 - val_acc: 0.9601\n",
      "Epoch 362/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1644 - acc: 0.9578 - val_loss: 0.1298 - val_acc: 0.9586\n",
      "Epoch 363/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1688 - acc: 0.9552 - val_loss: 0.1352 - val_acc: 0.9615\n",
      "Epoch 364/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1688 - acc: 0.9544 - val_loss: 0.1558 - val_acc: 0.9529\n",
      "Epoch 365/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1710 - acc: 0.9555 - val_loss: 0.1272 - val_acc: 0.9615\n",
      "Epoch 366/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1579 - acc: 0.9596 - val_loss: 0.1339 - val_acc: 0.9658\n",
      "Epoch 367/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1704 - acc: 0.9563 - val_loss: 0.1366 - val_acc: 0.9601\n",
      "Epoch 368/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1745 - acc: 0.9567 - val_loss: 0.1207 - val_acc: 0.9658\n",
      "Epoch 369/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1593 - acc: 0.9593 - val_loss: 0.1145 - val_acc: 0.9615\n",
      "Epoch 370/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1518 - acc: 0.9589 - val_loss: 0.1220 - val_acc: 0.9615\n",
      "Epoch 371/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1471 - acc: 0.9608 - val_loss: 0.1317 - val_acc: 0.9643\n",
      "Epoch 372/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1695 - acc: 0.9559 - val_loss: 0.1263 - val_acc: 0.9615\n",
      "Epoch 373/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1713 - acc: 0.9574 - val_loss: 0.1303 - val_acc: 0.9601\n",
      "Epoch 374/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1417 - acc: 0.9559 - val_loss: 0.1226 - val_acc: 0.9643\n",
      "Epoch 375/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1406 - acc: 0.9593 - val_loss: 0.1278 - val_acc: 0.9658\n",
      "Epoch 376/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1736 - acc: 0.9600 - val_loss: 0.1142 - val_acc: 0.9615\n",
      "Epoch 377/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1560 - acc: 0.9593 - val_loss: 0.1294 - val_acc: 0.9572\n",
      "Epoch 378/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1560 - acc: 0.9630 - val_loss: 0.1244 - val_acc: 0.9586\n",
      "Epoch 379/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1582 - acc: 0.9585 - val_loss: 0.1264 - val_acc: 0.9601\n",
      "Epoch 380/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1678 - acc: 0.9510 - val_loss: 0.1304 - val_acc: 0.9601\n",
      "Epoch 381/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1577 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9658\n",
      "Epoch 382/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1468 - acc: 0.9619 - val_loss: 0.1350 - val_acc: 0.9643\n",
      "Epoch 383/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1321 - acc: 0.9626 - val_loss: 0.1403 - val_acc: 0.9643\n",
      "Epoch 384/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1601 - acc: 0.9529 - val_loss: 0.1257 - val_acc: 0.9629\n",
      "Epoch 385/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1731 - acc: 0.9567 - val_loss: 0.1232 - val_acc: 0.9601\n",
      "Epoch 386/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1806 - acc: 0.9567 - val_loss: 0.1197 - val_acc: 0.9629\n",
      "Epoch 387/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1515 - acc: 0.9552 - val_loss: 0.1356 - val_acc: 0.9601\n",
      "Epoch 388/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1555 - acc: 0.9641 - val_loss: 0.1449 - val_acc: 0.9615\n",
      "Epoch 389/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1690 - acc: 0.9563 - val_loss: 0.1212 - val_acc: 0.9658\n",
      "Epoch 390/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1521 - acc: 0.9600 - val_loss: 0.1374 - val_acc: 0.9629\n",
      "Epoch 391/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1670 - acc: 0.9563 - val_loss: 0.1398 - val_acc: 0.9643\n",
      "Epoch 392/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1573 - acc: 0.9589 - val_loss: 0.1387 - val_acc: 0.9643\n",
      "Epoch 393/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1415 - acc: 0.9563 - val_loss: 0.1509 - val_acc: 0.9658\n",
      "Epoch 394/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1617 - acc: 0.9574 - val_loss: 0.1368 - val_acc: 0.9615\n",
      "Epoch 395/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1523 - acc: 0.9555 - val_loss: 0.1371 - val_acc: 0.9629\n",
      "Epoch 396/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1512 - acc: 0.9567 - val_loss: 0.1472 - val_acc: 0.9643\n",
      "Epoch 397/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1719 - acc: 0.9544 - val_loss: 0.1413 - val_acc: 0.9643\n",
      "Epoch 398/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1565 - acc: 0.9596 - val_loss: 0.1315 - val_acc: 0.9615\n",
      "Epoch 399/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1445 - acc: 0.9567 - val_loss: 0.1489 - val_acc: 0.9615\n",
      "Epoch 400/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1482 - acc: 0.9604 - val_loss: 0.1404 - val_acc: 0.9615\n",
      "Epoch 401/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1282 - acc: 0.9667 - val_loss: 0.1357 - val_acc: 0.9586\n",
      "Epoch 402/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1519 - acc: 0.9619 - val_loss: 0.1308 - val_acc: 0.9629\n",
      "Epoch 403/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1689 - acc: 0.9559 - val_loss: 0.1329 - val_acc: 0.9643\n",
      "Epoch 404/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1488 - acc: 0.9559 - val_loss: 0.1531 - val_acc: 0.9629\n",
      "Epoch 405/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1567 - acc: 0.9578 - val_loss: 0.1375 - val_acc: 0.9601\n",
      "Epoch 406/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1391 - acc: 0.9630 - val_loss: 0.1415 - val_acc: 0.9629\n",
      "Epoch 407/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1628 - acc: 0.9540 - val_loss: 0.1490 - val_acc: 0.9629\n",
      "Epoch 408/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1469 - acc: 0.9596 - val_loss: 0.1463 - val_acc: 0.9643\n",
      "Epoch 409/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1343 - acc: 0.9630 - val_loss: 0.1409 - val_acc: 0.9629\n",
      "Epoch 410/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1609 - acc: 0.9626 - val_loss: 0.1553 - val_acc: 0.9629\n",
      "Epoch 411/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1745 - acc: 0.9578 - val_loss: 0.1635 - val_acc: 0.9586\n",
      "Epoch 412/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1364 - acc: 0.9619 - val_loss: 0.1510 - val_acc: 0.9615\n",
      "Epoch 413/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1584 - acc: 0.9641 - val_loss: 0.1479 - val_acc: 0.9586\n",
      "Epoch 414/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1556 - acc: 0.9581 - val_loss: 0.1400 - val_acc: 0.9586\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1606 - acc: 0.9548 - val_loss: 0.1414 - val_acc: 0.9586\n",
      "Epoch 416/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1552 - acc: 0.9555 - val_loss: 0.1394 - val_acc: 0.9558\n",
      "Epoch 417/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1532 - acc: 0.9604 - val_loss: 0.1476 - val_acc: 0.9558\n",
      "Epoch 418/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1446 - acc: 0.9585 - val_loss: 0.1577 - val_acc: 0.9615\n",
      "Epoch 419/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1457 - acc: 0.9656 - val_loss: 0.1605 - val_acc: 0.9615\n",
      "Epoch 420/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1559 - acc: 0.9578 - val_loss: 0.1465 - val_acc: 0.9586\n",
      "Epoch 421/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1448 - acc: 0.9600 - val_loss: 0.1790 - val_acc: 0.9572\n",
      "Epoch 422/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1613 - acc: 0.9585 - val_loss: 0.1372 - val_acc: 0.9572\n",
      "Epoch 423/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1630 - acc: 0.9567 - val_loss: 0.1411 - val_acc: 0.9629\n",
      "Epoch 424/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1588 - acc: 0.9593 - val_loss: 0.1214 - val_acc: 0.9615\n",
      "Epoch 425/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1491 - acc: 0.9630 - val_loss: 0.1474 - val_acc: 0.9629\n",
      "Epoch 426/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1631 - acc: 0.9563 - val_loss: 0.1289 - val_acc: 0.9658\n",
      "Epoch 427/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1601 - acc: 0.9593 - val_loss: 0.1331 - val_acc: 0.9629\n",
      "Epoch 428/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1476 - acc: 0.9611 - val_loss: 0.1584 - val_acc: 0.9615\n",
      "Epoch 429/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1429 - acc: 0.9623 - val_loss: 0.1596 - val_acc: 0.9601\n",
      "Epoch 430/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1560 - acc: 0.9611 - val_loss: 0.1353 - val_acc: 0.9615\n",
      "Epoch 431/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1600 - acc: 0.9638 - val_loss: 0.1515 - val_acc: 0.9572\n",
      "Epoch 432/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1678 - acc: 0.9567 - val_loss: 0.1284 - val_acc: 0.9629\n",
      "Epoch 433/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1619 - acc: 0.9581 - val_loss: 0.1471 - val_acc: 0.9601\n",
      "Epoch 434/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1570 - acc: 0.9600 - val_loss: 0.1432 - val_acc: 0.9615\n",
      "Epoch 435/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1455 - acc: 0.9570 - val_loss: 0.1383 - val_acc: 0.9615\n",
      "Epoch 436/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1316 - acc: 0.9645 - val_loss: 0.1655 - val_acc: 0.9601\n",
      "Epoch 437/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1641 - acc: 0.9589 - val_loss: 0.1623 - val_acc: 0.9601\n",
      "Epoch 438/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1517 - acc: 0.9604 - val_loss: 0.1774 - val_acc: 0.9601\n",
      "Epoch 439/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1639 - acc: 0.9611 - val_loss: 0.1595 - val_acc: 0.9629\n",
      "Epoch 440/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1477 - acc: 0.9596 - val_loss: 0.1458 - val_acc: 0.9643\n",
      "Epoch 441/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1642 - acc: 0.9570 - val_loss: 0.1284 - val_acc: 0.9601\n",
      "Epoch 442/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1566 - acc: 0.9563 - val_loss: 0.1425 - val_acc: 0.9615\n",
      "Epoch 443/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1465 - acc: 0.9611 - val_loss: 0.1747 - val_acc: 0.9572\n",
      "Epoch 444/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1589 - acc: 0.9608 - val_loss: 0.1400 - val_acc: 0.9629\n",
      "Epoch 445/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1454 - acc: 0.9596 - val_loss: 0.1505 - val_acc: 0.9601\n",
      "Epoch 446/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1549 - acc: 0.9630 - val_loss: 0.1594 - val_acc: 0.9601\n",
      "Epoch 447/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1531 - acc: 0.9559 - val_loss: 0.1460 - val_acc: 0.9601\n",
      "Epoch 448/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1331 - acc: 0.9634 - val_loss: 0.1376 - val_acc: 0.9615\n",
      "Epoch 449/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1347 - acc: 0.9645 - val_loss: 0.1692 - val_acc: 0.9601\n",
      "Epoch 450/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1460 - acc: 0.9596 - val_loss: 0.1505 - val_acc: 0.9629\n",
      "Epoch 451/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1287 - acc: 0.9682 - val_loss: 0.1622 - val_acc: 0.9572\n",
      "Epoch 452/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1523 - acc: 0.9578 - val_loss: 0.1463 - val_acc: 0.9615\n",
      "Epoch 453/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1396 - acc: 0.9615 - val_loss: 0.1652 - val_acc: 0.9572\n",
      "Epoch 454/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1598 - acc: 0.9611 - val_loss: 0.1736 - val_acc: 0.9586\n",
      "Epoch 455/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1472 - acc: 0.9615 - val_loss: 0.1520 - val_acc: 0.9615\n",
      "Epoch 456/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1324 - acc: 0.9664 - val_loss: 0.1601 - val_acc: 0.9615\n",
      "Epoch 457/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1478 - acc: 0.9600 - val_loss: 0.1453 - val_acc: 0.9601\n",
      "Epoch 458/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1465 - acc: 0.9645 - val_loss: 0.1577 - val_acc: 0.9615\n",
      "Epoch 459/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1464 - acc: 0.9600 - val_loss: 0.1417 - val_acc: 0.9615\n",
      "Epoch 460/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1550 - acc: 0.9533 - val_loss: 0.1363 - val_acc: 0.9615\n",
      "Epoch 461/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1437 - acc: 0.9638 - val_loss: 0.1466 - val_acc: 0.9629\n",
      "Epoch 462/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1431 - acc: 0.9600 - val_loss: 0.1492 - val_acc: 0.9615\n",
      "Epoch 463/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1480 - acc: 0.9604 - val_loss: 0.1469 - val_acc: 0.9629\n",
      "Epoch 464/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1389 - acc: 0.9596 - val_loss: 0.1418 - val_acc: 0.9643\n",
      "Epoch 465/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1472 - acc: 0.9638 - val_loss: 0.1439 - val_acc: 0.9615\n",
      "Epoch 466/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1476 - acc: 0.9615 - val_loss: 0.1553 - val_acc: 0.9643\n",
      "Epoch 467/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1634 - acc: 0.9593 - val_loss: 0.1230 - val_acc: 0.9658\n",
      "Epoch 468/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1408 - acc: 0.9623 - val_loss: 0.1461 - val_acc: 0.9643\n",
      "Epoch 469/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1325 - acc: 0.9660 - val_loss: 0.1389 - val_acc: 0.9615\n",
      "Epoch 470/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1293 - acc: 0.9615 - val_loss: 0.1383 - val_acc: 0.9658\n",
      "Epoch 471/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1360 - acc: 0.9641 - val_loss: 0.1381 - val_acc: 0.9658\n",
      "Epoch 472/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1628 - acc: 0.9623 - val_loss: 0.1437 - val_acc: 0.9672\n",
      "Epoch 473/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1530 - acc: 0.9611 - val_loss: 0.1466 - val_acc: 0.9629\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1665 - acc: 0.9596 - val_loss: 0.1312 - val_acc: 0.9615\n",
      "Epoch 475/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1507 - acc: 0.9581 - val_loss: 0.1337 - val_acc: 0.9615\n",
      "Epoch 476/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1756 - acc: 0.9563 - val_loss: 0.1207 - val_acc: 0.9658\n",
      "Epoch 477/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1436 - acc: 0.9623 - val_loss: 0.1388 - val_acc: 0.9643\n",
      "Epoch 478/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1603 - acc: 0.9626 - val_loss: 0.1485 - val_acc: 0.9615\n",
      "Epoch 479/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1439 - acc: 0.9615 - val_loss: 0.1463 - val_acc: 0.9629\n",
      "Epoch 480/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1599 - acc: 0.9574 - val_loss: 0.1381 - val_acc: 0.9658\n",
      "Epoch 481/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1511 - acc: 0.9611 - val_loss: 0.1504 - val_acc: 0.9672\n",
      "Epoch 482/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1362 - acc: 0.9682 - val_loss: 0.1523 - val_acc: 0.9643\n",
      "Epoch 483/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1483 - acc: 0.9634 - val_loss: 0.1428 - val_acc: 0.9629\n",
      "Epoch 484/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1432 - acc: 0.9623 - val_loss: 0.1426 - val_acc: 0.9629\n",
      "Epoch 485/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.1549 - acc: 0.9596 - val_loss: 0.1572 - val_acc: 0.9658\n",
      "Epoch 486/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1589 - acc: 0.9570 - val_loss: 0.1514 - val_acc: 0.9615\n",
      "Epoch 487/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1428 - acc: 0.9630 - val_loss: 0.1484 - val_acc: 0.9629\n",
      "Epoch 488/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1687 - acc: 0.9596 - val_loss: 0.1471 - val_acc: 0.9629\n",
      "Epoch 489/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1386 - acc: 0.9679 - val_loss: 0.1380 - val_acc: 0.9629\n",
      "Epoch 490/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1412 - acc: 0.9626 - val_loss: 0.1150 - val_acc: 0.9629\n",
      "Epoch 491/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1358 - acc: 0.9649 - val_loss: 0.1283 - val_acc: 0.9629\n",
      "Epoch 492/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1443 - acc: 0.9664 - val_loss: 0.1275 - val_acc: 0.9615\n",
      "Epoch 493/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1376 - acc: 0.9630 - val_loss: 0.1260 - val_acc: 0.9601\n",
      "Epoch 494/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1381 - acc: 0.9638 - val_loss: 0.1218 - val_acc: 0.9629\n",
      "Epoch 495/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1286 - acc: 0.9638 - val_loss: 0.1444 - val_acc: 0.9629\n",
      "Epoch 496/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1372 - acc: 0.9578 - val_loss: 0.1551 - val_acc: 0.9629\n",
      "Epoch 497/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1388 - acc: 0.9623 - val_loss: 0.1464 - val_acc: 0.9643\n",
      "Epoch 498/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1571 - acc: 0.9604 - val_loss: 0.1387 - val_acc: 0.9672\n",
      "Epoch 499/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1542 - acc: 0.9596 - val_loss: 0.1440 - val_acc: 0.9658\n",
      "Epoch 500/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1567 - acc: 0.9638 - val_loss: 0.1304 - val_acc: 0.9629\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_norm, Y_train, validation_data=(X_test_norm, Y_test), epochs=500, batch_size=32, verbose=1)#, callbacks= [earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c3bbd0978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "model.save('pose_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated pose:\n",
      "STANDING: \t0.013973521\n",
      "BENDING: \t0.034460872\n",
      "CROUCHING: \t0.95156556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c3ad70898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing on single example\n",
    "LABELS = [\"STANDING\", \"BENDING\", \"CROUCHING\"]\n",
    "\n",
    "X_sample = load_X('dataset/X_sample.txt')\n",
    "X_sample_norm = norm_X(X_sample)\n",
    "y_out = model.predict(X_sample_norm[0].reshape(1, 36))\n",
    "\n",
    "print(\"Estimated pose:\")\n",
    "for idx in range(len(LABELS)):\n",
    "    print(LABELS[idx] + \": \\t\" + str(y_out[0][idx]))\n",
    "plot(X_sample[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
