opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 88.5057465251052

best_acc1: 88.5057468007155

best_acc1: 88.5057468007155

best_acc1: 88.50574663785487

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 91.1330039364168

best_acc1: 91.13300487599741

best_acc1: 91.13300443752645

best_acc1: 91.13300448763742

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

best_acc1: 93.92446589978849

best_acc1: 93.92446601253816

best_acc1: 93.92446534856786

best_acc1: 93.92446562417818

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694498597694

best_acc1: 97.53694498597694

best_acc1: 97.53694553719757

best_acc1: 97.53694526158726

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694498597694

best_acc1: 97.53694526158726

best_acc1: 97.53694553719757

best_acc1: 97.53694498597694

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694498597694

best_acc1: 97.53694498597694

best_acc1: 97.53694526158726

best_acc1: 97.53694553719757

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694498597694

best_acc1: 97.53694553719757

best_acc1: 97.53694498597694

best_acc1: 97.53694526158726

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694526158726

best_acc1: 97.53694498597694

best_acc1: 97.53694498597694

best_acc1: 97.53694553719757

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694526158726

best_acc1: 97.53694498597694

best_acc1: 97.53694553719757

best_acc1: 97.53694498597694

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!
opt.local_rank is not zero!!!

opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!

opt.local_rank is not zero!!!
opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


opt.local_rank is not zero!!!opt.local_rank is not zero!!!opt.local_rank is not zero!!!


best_acc1: 97.53694526158726

best_acc1: 97.53694498597694

best_acc1: 97.53694498597694

best_acc1: 97.53694553719757

Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10 
main.py: error: unrecognized arguments: --early_stopping_patience 10 
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'main.py', '--local_rank=1', '--data_name', 'APTOS-2019-Blindness-Detection', '--data_path', '/data/AutoML_compete/aptos2019-blindness-detection/split', '--model', 'resnetv2_50x1_bitm_in21k', '--augmentation', 'original-mstd0.5', '--lr', '0.005', '--epochs', '30', '--batch-size', '64', '--early_stopping_patience', '10 ']' returned non-zero exit status 2.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 38401
Killing subprocess 38402
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'main.py', '--local_rank=1', '--data_name', 'APTOS-2019-Blindness-Detection', '--data_path', '/data/AutoML_compete/aptos2019-blindness-detection/split', '--model', 'resnetv2_50x1_bitm_in21k', '--augmentation', 'original-mstd0.5', '--lr', '0.005', '--epochs', '30', '--batch-size', '64', '--early_stopping_patience', '10', ' ']' returned non-zero exit status 2.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 38518
Killing subprocess 38519
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'main.py', '--local_rank=1', '--data_name', 'APTOS-2019-Blindness-Detection', '--data_path', '/data/AutoML_compete/aptos2019-blindness-detection/split', '--model', 'resnetv2_50x1_bitm_in21k', '--augmentation', 'original-mstd0.5', '--lr', '0.005', '--epochs', '30', '--batch-size', '64', '--early_stopping_patience', '10', ' ']' returned non-zero exit status 2.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 38652
Killing subprocess 38653
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.

/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'main.py', '--local_rank=1', '--data_name', 'APTOS-2019-Blindness-Detection', '--data_path', '/data/AutoML_compete/aptos2019-blindness-detection/split', '--model', 'resnetv2_50x1_bitm_in21k', '--lr', '0.005', '--epochs', '30', '--batch-size', '64', '--augmentation', 'original-mstd0.5', '--early_stopping_patience', '10', ' ']' returned non-zero exit status 2.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 38808
Killing subprocess 38809
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
usage: main.py [-h] [--data_name DATA_NAME] [--data_path DATA_PATH]
               [--data-backend BACKEND] [--interpolation INTERPOLATION]
               [--model MODEL] [--pretrained] [-j N] [--epochs N]
               [--run-epochs N] [--start-epoch N]
               [--early-stopping-patience N] [--image-size IMAGE_SIZE] [-b N]
               [--optimizer-batch-size N] [--lr LR] [--lr-schedule SCHEDULE]
               [--warmup E] [--label-smoothing S] [--mixup ALPHA]
               [--optimizer {sgd,rmsprop}] [--momentum M] [--wd W]
               [--bn-weight-decay] [--rmsprop-alpha RMSPROP_ALPHA]
               [--rmsprop-eps RMSPROP_EPS] [--nesterov] [--use-ema USE_EMA]
               [--augmentation {None,autoaugment,original-mstd0.5,rand-m9-n3-mstd0.5,augmix-m5-w4-d2}]
               [--log_interval N] [--resume PATH] [--evaluate]
               [--training-only] [--no-checkpoints]
               [--checkpoint-filename CHECKPOINT_FILENAME] [--seed S] [--amp]
               [--apex-amp] [--native-amp]
               [--static-loss-scale STATIC_LOSS_SCALE] [--dynamic-loss-scale]
               [--local_rank LOCAL_RANK] [--world-size WORLD_SIZE]
               [--rank RANK] [--memory-format {nchw,nhwc}]
               [--output-dir OUTPUT_DIR] [--multiprocessing-distributed]
main.py: error: unrecognized arguments: --early_stopping_patience 10  
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yiran.wu/.local/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'main.py', '--local_rank=1', '--data_name', 'APTOS-2019-Blindness-Detection', '--data_path', '/data/AutoML_compete/aptos2019-blindness-detection/split', '--model', 'resnetv2_101x1_bitm_in21k', '--lr', '0.005', '--epochs', '30', '--batch-size', '32', '--early_stopping_patience', '10', ' ']' returned non-zero exit status 2.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 38567
Killing subprocess 38568
Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.Please install DALI from https://www.github.com/NVIDIA/DALI to run this example.

/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
/data/autodl/benchmark/torch_pipeline/autotorch/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  "pytorch_quantization module not found, quantization will not be available"
Added key: store_based_barrier_key:1 to store for rank: 1
Using seed = 42
Added key: store_based_barrier_key:1 to store for rank: 0
Using seed = 42
/home/yiran.wu/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yiran.wu/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:804: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yiran.wu/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yiran.wu/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 18548
Killing subprocess 18549
Main process received SIGINT, exiting
